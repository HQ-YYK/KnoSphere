from fastapi import FastAPI, UploadFile, File, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware  # æ–°å¢å¯¼å…¥
from contextlib import asynccontextmanager
from sqlmodel import Session, text
import os
import io
from services.search import hybrid_search

# æ•°æ®åº“å’Œæ¨¡å‹å¯¼å…¥
from database import init_db, engine, get_session
from models import User, Document
from services.embedding import generate_vector

from fastapi.responses import StreamingResponse
from services.llm import get_llm_service
from services.search import hybrid_search
import json

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    print("ğŸš€ å¯åŠ¨ KnoSphere API...")

    # æ˜¾ç¤ºå½“å‰Embeddingé…ç½®
    provider = os.getenv("EMBEDDING_PROVIDER", "openai")
    model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
    dim = os.getenv("VECTOR_DIM", "1536")
    print(f"ğŸ¤– å½“å‰Embeddingé…ç½®: {provider} / {model} / {dim}ç»´")
    
    with engine.connect() as conn:
        # æ¿€æ´»å‘é‡æ‰©å±•
        conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
        conn.commit()
    
    init_db()  # è¿™ä¼šåˆ›å»ºæ‰€æœ‰è¡¨ï¼ŒåŒ…æ‹¬ User å’Œ Document
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    yield
    
    # å…³é—­æ—¶æ‰§è¡Œ
    print("ğŸ‘‹ å…³é—­ KnoSphere API...")

app = FastAPI(
    title="KnoSphere API",
    description="2026 ä¼ä¸šçº§æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ",
    version="1.0.0",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰æ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰å¤´éƒ¨
)


@app.get("/")
async def root():
    return {"message": "æ¬¢è¿ä½¿ç”¨ KnoSphere API - 2026 ä¼ä¸šçº§æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ"}

@app.get("/health")
async def health():
    return {
        "status": "healthy", 
        "service": "KnoSphere API",
        "embedding_provider": os.getenv("EMBEDDING_PROVIDER", "openai"),
        "embedding_model": os.getenv("EMBEDDING_MODEL", "text-embedding-3-small"),
        "vector_dimension": os.getenv("VECTOR_DIM", "1536")
    }

@app.get("/documents")
async def list_documents(
    db: Session = Depends(get_session),
    limit: int = 10,
    offset: int = 0
):
    """è·å–æ–‡æ¡£åˆ—è¡¨"""
    documents = db.query(Document).offset(offset).limit(limit).all()
    return {
        "total": db.query(Document).count(),
        "documents": [
            {
                "id": doc.id,
                "title": doc.title,
                "created_at": doc.created_at,
                "content_preview": doc.content[:100] + "..." if len(doc.content) > 100 else doc.content
            }
            for doc in documents
        ]
    }

@app.post("/upload")
async def upload_document(
    file: UploadFile = File(...), 
    db: Session = Depends(get_session)
):
    """
    ä¸Šä¼ æ–‡æ¡£å¹¶ç”Ÿæˆå‘é‡
    æ”¯æŒæ ¼å¼ï¼š.txt, .md, .pdf, .docx
    """
    # 1. éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.txt', '.md', '.pdf', '.docx'}
    file_ext = os.path.splitext(file.filename)[1].lower()
    
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒæ ¼å¼: {', '.join(allowed_extensions)}"
        )
    
    # 2. è¯»å–æ–‡ä»¶å†…å®¹
    try:
        content = await file.read()
        
        # å¤„ç†ä¸åŒæ–‡ä»¶ç±»å‹
        if file_ext == '.pdf':
            # PDF å¤„ç† - éœ€è¦é¢å¤–çš„ä¾èµ–
            try:
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(content))
                text_content = ""
                for page in pdf_reader.pages:
                    text_content += page.extract_text()
            except ImportError:
                # å¦‚æœæœªå®‰è£… PyPDF2ï¼Œæç¤ºå®‰è£…
                raise HTTPException(
                    status_code=400,
                    detail="PDF å¤„ç†éœ€è¦å®‰è£… PyPDF2ã€‚è¯·è¿è¡Œ: uv add PyPDF2"
                )
        elif file_ext == '.docx':
            # DOCX å¤„ç†
            try:
                import docx
                doc = docx.Document(io.BytesIO(content))
                text_content = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            except ImportError:
                raise HTTPException(
                    status_code=400,
                    detail="DOCX å¤„ç†éœ€è¦å®‰è£… python-docxã€‚è¯·è¿è¡Œ: uv add python-docx"
                )
        else:
            # æ–‡æœ¬æ–‡ä»¶å¤„ç†
            text_content = content.decode("utf-8")
            
    except UnicodeDecodeError:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ä½¿ç”¨ UTF-8 ç¼–ç ")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    # 3. æ£€æŸ¥æ–‡æœ¬é•¿åº¦
    if len(text_content.strip()) == 0:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹ä¸ºç©º")
    
    # 4. ç”Ÿæˆå‘é‡ (AI æ ¸å¿ƒæ­¥éª¤)
    try:
        vector = await generate_vector(text_content)
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"å‘é‡ç”Ÿæˆå¤±è´¥: {str(e)}ã€‚è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡"
        )

    # 5. å­˜å‚¨åˆ° PostgreSQL 17
    try:
        new_doc = Document(
            title=file.filename,
            content=text_content,
            embedding=vector  # å­˜å…¥æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„ Vector å­—æ®µ
        )
        
        db.add(new_doc)
        db.commit()
        db.refresh(new_doc)
        
        return {
            "message": "ä¸Šä¼ æˆåŠŸ", 
            "document_id": new_doc.id,
            "title": new_doc.title,
            "vector_dimensions": len(vector) if vector else 0,
            "content_length": len(text_content)
        }
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"æ•°æ®åº“å­˜å‚¨å¤±è´¥: {str(e)}")


@app.get("/query")
async def query_knowledge_base(
    q: str,
    top_k: int= 15,
    final_k: int = 3,
    db: Session = Depends(get_session)
):
    """
    æ™ºèƒ½æŸ¥è¯¢çŸ¥è¯†åº“
    
    å‚æ•°ï¼š
    - q: æŸ¥è¯¢é—®é¢˜
    - top_k: ç²—æ’é˜¶æ®µè¿”å›çš„æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤15ï¼‰
    - final_k: ç²¾æ’åæœ€ç»ˆè¿”å›çš„æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤3ï¼‰
    """
    if not q or not q.strip():
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥é—®é¢˜")
    
    if len(q.strip()) > 1000:
        raise HTTPException(status_code=400, detail="é—®é¢˜è¿‡é•¿ï¼Œè¯·ç²¾ç®€åˆ°1000å­—ç¬¦ä»¥å†…")
    
    try:
        print(f"ğŸ” å¼€å§‹æœç´¢: {q}")
        results = await hybrid_search(q, db, top_k=top_k, final_k=final_k)
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        formatted_results = []
        for i, doc in enumerate(results):
            formatted_results.append({
                "rank": i + 1,
                "id": doc.get("id"),
                "title": doc.get("title", "æ— æ ‡é¢˜"),
                "score": round(doc.get("score", 0) * 100, 2),  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                "content_preview": doc.get("content", "")[:200] + "..." if len(doc.get("content", "")) > 200 else doc.get("content", ""),
                "created_at": doc.get("created_at")
            })
        
        return {
            "query": q,
            "total_results": len(results),
            "results": formatted_results
        }
        
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")

@app.get("/documents/{document_id}")
async def get_document(
    document_id: int,
    db: Session = Depends(get_session)
):
    """è·å–ç‰¹å®šæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯"""
    document = db.get(Document, document_id)
    if not document:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
    
    return {
        "id": document.id,
        "title": document.title,
        "content": document.content,
        "created_at": document.created_at,
        "vector_dimensions": len(document.embedding) if document.embedding else 0
    }

@app.get("/search-test")
async def search_test(
    q: str = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
    db: Session = Depends(get_session)
):
    """æœç´¢æµ‹è¯•ç«¯ç‚¹ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰"""
    try:
        results = await hybrid_search(q, db, top_k=5, final_k=3)
        
        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ–‡æ¡£ï¼Œåˆ›å»ºä¸€äº›æµ‹è¯•æ•°æ®
        if not results:
            from services.embedding import generate_vector
            import datetime
            
            # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
            test_docs = [
                {
                    "title": "äººå·¥æ™ºèƒ½ç®€ä»‹",
                    "content": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›é€ èƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨ã€‚"
                },
                {
                    "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
                    "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚"
                },
                {
                    "title": "æ·±åº¦å­¦ä¹ ",
                    "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚"
                }
            ]
            
            for doc_data in test_docs:
                vector = await generate_vector(doc_data["content"])
                new_doc = Document(
                    title=doc_data["title"],
                    content=doc_data["content"],
                    embedding=vector,
                    created_at=datetime.datetime.utcnow()
                )
                db.add(new_doc)
            
            db.commit()
            
            # é‡æ–°æœç´¢
            results = await hybrid_search(q, db, top_k=5, final_k=3)
        
        return {
            "query": q,
            "results": results,
            "message": "æµ‹è¯•æˆåŠŸ" if results else "æ•°æ®åº“ä¸ºç©ºï¼Œå·²åˆ›å»ºæµ‹è¯•æ•°æ®"
        }
        
    except Exception as e:
        return {"error": str(e)}


@app.post("/chat")
async def chat(
    request: dict,
    db: Session = Depends(get_session)
):
    """
    èŠå¤©æ¥å£ - æµå¼å“åº”
    
    è¯·æ±‚ä½“ï¼š
    {
        "query": "ç”¨æˆ·çš„é—®é¢˜",
        "top_k": 10,  # å¯é€‰ï¼Œæ£€ç´¢æ–‡æ¡£æ•°é‡
        "final_k": 3   # å¯é€‰ï¼Œæœ€ç»ˆä½¿ç”¨æ–‡æ¡£æ•°é‡
    }
    """
    query = request.get("query", "").strip()
    top_k = request.get("top_k", 10)
    final_k = request.get("final_k", 3)
    
    if not query:
        return StreamingResponse(
            iter(["âŒ è¯·è¾“å…¥é—®é¢˜"]),
            media_type="text/plain"
        )
    
    # 1. æ£€ç´¢æœ€ç›¸å…³çš„çŸ¥è¯†
    try:
        docs = await hybrid_search(query, db, top_k=top_k, final_k=final_k)
        
        if not docs:
            return StreamingResponse(
                iter(["ğŸ” çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚è¯·å…ˆä¸Šä¼ ä¸€äº›æ–‡æ¡£ï¼Œæˆ–è€…æ¢ä¸ªé—®é¢˜è¯•è¯•ã€‚"]),
                media_type="text/plain"
            )
        
        # 2. æ‹¼æ¥ä¸Šä¸‹æ–‡
        context_parts = []
        for i, doc in enumerate(docs[:final_k]):  # ä½¿ç”¨ final_k é™åˆ¶
            context_parts.append(f"ã€æ–‡æ¡£{i+1}ã€‘{doc.get('title', 'æ— æ ‡é¢˜')}")
            content_preview = doc.get('content', '')[:500] + "..." if len(doc.get('content', '')) > 500 else doc.get('content', '')
            context_parts.append(f"å†…å®¹ï¼š{content_preview}")
            context_parts.append(f"ç›¸å…³åº¦ï¼š{doc.get('score', 0):.2%}")
            context_parts.append("---")
        
        context_text = "\n".join(context_parts)
        
        # 3. è·å– LLM æœåŠ¡
        llm_service = get_llm_service()
        
        # 4. è¿”å›æµå¼å“åº”
        async def generate():
            # å…ˆè¿”å›æ£€ç´¢ç»“æœæ‘˜è¦
            yield f"ğŸ” å·²ä¸ºæ‚¨æ£€ç´¢åˆ° {len(docs)} ç¯‡ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨å‰ {min(final_k, len(docs))} ç¯‡ç”Ÿæˆå›ç­”ï¼š\n\n"
            await asyncio.sleep(0.1)
            
            # ç„¶åæµå¼è¿”å› AI å›ç­”
            async for chunk in llm_service.stream_response(query, context_text):
                yield chunk
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"  # ç¦ç”¨ Nginx ç¼“å†²
            }
        )
        
    except Exception as e:
        print(f"âŒ èŠå¤©å¤„ç†å¤±è´¥: {e}")
        return StreamingResponse(
            iter([f"âŒ å¤„ç†è¯·æ±‚æ—¶å‡ºé”™ï¼š{str(e)}"]),
            media_type="text/plain"
        )

@app.get("/chat-test")
async def chat_test(
    query: str = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    db: Session = Depends(get_session)
):
    """èŠå¤©æµ‹è¯•ç«¯ç‚¹ï¼ˆéæµå¼ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰"""
    if not query:
        return {"error": "è¯·è¾“å…¥é—®é¢˜"}
    
    try:
        # æ£€ç´¢æ–‡æ¡£
        docs = await hybrid_search(query, db, top_k=5, final_k=2)
        
        if not docs:
            return {"answer": "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚", "documents": []}
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for i, doc in enumerate(docs):
            context_parts.append(f"ã€æ–‡æ¡£{i+1}ã€‘{doc.get('title', 'æ— æ ‡é¢˜')}")
            context_parts.append(f"å†…å®¹ï¼š{doc.get('content', '')[:300]}...")
            context_parts.append("---")
        
        context_text = "\n".join(context_parts)
        
        # è·å– LLM æœåŠ¡
        llm_service = get_llm_service()
        
        # æ”¶é›†æµå¼å“åº”
        full_response = ""
        async for chunk in llm_service.stream_response(query, context_text):
            full_response += chunk
        
        return {
            "query": query,
            "answer": full_response,
            "documents_used": [
                {
                    "title": doc.get("title"),
                    "score": f"{doc.get('score', 0):.2%}",
                    "content_preview": doc.get("content", "")[:100] + "..."
                }
                for doc in docs[:2]
            ]
        }
        
    except Exception as e:
        return {"error": str(e)}

# å¦‚æœéœ€è¦æ·»åŠ æ›´å¤šæ–‡ä»¶æ ¼å¼å¤„ç†ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶å®‰è£…ç›¸åº”ä¾èµ–
# @app.on_event("startup")
# async def check_dependencies():
#     """æ£€æŸ¥å¯é€‰ä¾èµ–"""
#     try:
#         import PyPDF2
#         print("âœ… PyPDF2 å·²å®‰è£…ï¼Œæ”¯æŒ PDF å¤„ç†")
#     except ImportError:
#         print("âš ï¸  PyPDF2 æœªå®‰è£…ï¼ŒPDF æ–‡ä»¶å¤„ç†å°†ä¸å¯ç”¨")
#     
#     try:
#         import docx
#         print("âœ… python-docx å·²å®‰è£…ï¼Œæ”¯æŒ DOCX å¤„ç†")
#     except ImportError:
#         print("âš ï¸  python-docx æœªå®‰è£…ï¼ŒDOCX æ–‡ä»¶å¤„ç†å°†ä¸å¯ç”¨")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
    )
from fastapi import FastAPI, UploadFile, File, Depends, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.security import OAuth2PasswordRequestForm
from contextlib import asynccontextmanager
from sqlmodel import Session, select
from typing import List, Optional
import os
import uuid
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path

from core.auth import ACCESS_TOKEN_EXPIRE_MINUTES, LoginRequest, Token, UserCreate, PasswordChange, get_current_active_user
from core.database_middleware import get_secure_db

# å¯¼å…¥ Celery ä»»åŠ¡
from tasks.document_tasks import process_large_document, batch_process_documents
from tasks.celery_app import celery_app


from core.logger import logger, log_api_response
from database import get_db, init_db, engine
from models import Document, User

from services.agentic_chat import get_agentic_chat_service
from services.tools import get_tool_manager

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ å¯åŠ¨ KnoSphere API...")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    with engine.connect() as conn:
        from sqlmodel import text
        conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
        conn.commit()
    init_db()
    
    logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    yield
    
    logger.info("ğŸ‘‹ å…³é—­ KnoSphere API...")

app = FastAPI(
    title="KnoSphere API",
    description="2026 ä¼ä¸šçº§æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ - åˆ†å¸ƒå¼å¼‚æ­¥å¤„ç†",
    version="2.1.0",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


from core.database_middleware import DatabaseSessionMiddleware
app.add_middleware(DatabaseSessionMiddleware)

# ==================== è®¤è¯è·¯ç”± ====================
@app.post("/auth/register", response_model=dict)
async def register(
    user_data: UserCreate,
    db: Session = Depends(get_db)
):
    """ç”¨æˆ·æ³¨å†Œ"""
    from core.auth import AuthService
    
    auth_service = AuthService()
    
    # æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦å·²å­˜åœ¨
    existing_user = db.exec(
        select(User).where(User.username == user_data.username)
    ).first()
    
    if existing_user:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åå·²å­˜åœ¨"
        )
    
    # æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²å­˜åœ¨
    existing_email = db.exec(
        select(User).where(User.email == user_data.email)
    ).first()
    
    if existing_email:
        raise HTTPException(
            status_code=400,
            detail="é‚®ç®±å·²å­˜åœ¨"
        )
    
    # åˆ›å»ºç”¨æˆ·
    hashed_password = auth_service.get_password_hash(user_data.password)
    
    user = User(
        username=user_data.username,
        email=user_data.email,
        password_hash=hashed_password,
        is_active=True,
        permissions={"documents": ["read", "write"]}
    )
    
    db.add(user)
    db.commit()
    db.refresh(user)
    
    return {
        "id": user.id,
        "username": user.username,
        "email": user.email,
        "message": "æ³¨å†ŒæˆåŠŸ"
    }

@app.post("/auth/login")
async def login(
    login_data: LoginRequest,  # ä½¿ç”¨ LoginRequest è€Œä¸æ˜¯ OAuth2PasswordRequestForm
    db: Session = Depends(get_db)
):
    """ç”¨æˆ·ç™»å½•"""
    try:
        from core.auth import AuthService
        # è®¤è¯ç”¨æˆ·
        user = await AuthService.authenticate_user(login_data, db)
        
        if not user:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        # åˆ›å»ºè®¿é—®ä»¤ç‰Œ
        access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = AuthService.create_access_token(
            data={"sub": str(user.id), "username": user.username},  # ç¡®ä¿ user.id è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            expires_delta=access_token_expires
        )
        
        # è¿”å›ä»¤ç‰Œ - ç¡®ä¿ user.id è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return Token(
            access_token=access_token,
            token_type="bearer",
            expires_in=ACCESS_TOKEN_EXPIRE_MINUTES * 60,
            user_id=str(user.id),  # è¿™é‡Œå¿…é¡»è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            username=user.username,
            permissions=user.permissions or {}
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç™»å½•å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ç™»å½•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        )


@app.get("/auth/me", response_model=dict)
async def get_me(
    current_user: User = Depends(get_current_active_user)
):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    return current_user.to_dict()

@app.post("/auth/change-password")
async def change_password(
    password_data: PasswordChange,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """ä¿®æ”¹å¯†ç """
    from core.auth import AuthService
    
    auth_service = AuthService()
    
    # éªŒè¯å½“å‰å¯†ç 
    if not auth_service.verify_password(
        password_data.current_password, 
        current_user.password_hash
    ):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="å½“å‰å¯†ç é”™è¯¯"
        )
    
    # æ›´æ–°å¯†ç 
    current_user.password_hash = auth_service.get_password_hash(
        password_data.new_password
    )
    db.add(current_user)
    db.commit()
    
    return {"message": "å¯†ç ä¿®æ”¹æˆåŠŸ"}


# ==================== å¼‚æ­¥ä¸Šä¼ æ¥å£ ====================

@app.post("/upload/async")
async def upload_large_document_async(
    file: UploadFile = File(...),
    user_id: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    å¼‚æ­¥ä¸Šä¼ å¤§æ–‡æ¡£
    
    ç«‹å³è¿”å›ä»»åŠ¡IDï¼Œæ–‡æ¡£åœ¨åå°å¤„ç†
    """
    start_time = datetime.now(timezone.utc)
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.txt', '.md', '.pdf', '.docx'}
    file_ext = os.path.splitext(file.filename)[1].lower()
    
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒæ ¼å¼: {', '.join(allowed_extensions)}"
        )
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    file_id = str(uuid.uuid4())
    temp_filename = f"{file_id}{file_ext}"
    temp_filepath = UPLOAD_DIR / temp_filename
    
    try:
        # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        content = await file.read()
        with open(temp_filepath, "wb") as f:
            f.write(content)
        
        file_size = len(content) / (1024 * 1024)  # MB
        logger.info(f"ğŸ“¥ æ–‡ä»¶å·²ä¿å­˜: {temp_filepath} ({file_size:.2f}MB)")
        
        # åˆ›å»ºæ–‡æ¡£è®°å½•ï¼ˆåˆå§‹çŠ¶æ€ï¼‰
        document = Document(
            title=file.filename,
            content=f"æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­... ({file_size:.2f}MB)",
            user_id=user_id
        )
        db.add(document)
        db.commit()
        db.refresh(document)
        
        # è§¦å‘å¼‚æ­¥å¤„ç†ä»»åŠ¡
        task = process_large_document.delay(
            str(temp_filepath),
            document.id,
            user_id
        )
        
        response_time = time.time() - start_time
        
        log_api_response("/upload/async", 200, response_time)
        
        return {
            "message": "å¤§æ–‡ä»¶å·²è¿›å…¥åå°å¤„ç†æµæ°´çº¿",
            "task_id": task.id,
            "document_id": document.id,
            "filename": file.filename,
            "file_size_mb": round(file_size, 2),
            "estimated_time": "å¤„ç†æ—¶é—´å–å†³äºæ–‡ä»¶å¤§å°å’Œå†…å®¹å¤æ‚åº¦",
            "status_url": f"/task/status/{task.id}",
            "document_url": f"/documents/{document.id}"
        }
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_filepath.exists():
            temp_filepath.unlink()
        
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/upload/batch")
async def upload_batch_documents(
    files: List[UploadFile] = File(...),
    user_id: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡ä¸Šä¼ æ–‡æ¡£
    """
    if len(files) > 10:
        raise HTTPException(status_code=400, detail="ä¸€æ¬¡æœ€å¤šä¸Šä¼ 10ä¸ªæ–‡ä»¶")
    
    file_paths = []
    document_ids = []
    
    try:
        for file in files:
            # éªŒè¯æ–‡ä»¶ç±»å‹
            allowed_extensions = {'.txt', '.md', '.pdf', '.docx'}
            file_ext = os.path.splitext(file.filename)[1].lower()
            
            if file_ext not in allowed_extensions:
                raise HTTPException(
                    status_code=400, 
                    detail=f"æ–‡ä»¶ {file.filename} æ ¼å¼ä¸æ”¯æŒ"
                )
            
            # ä¿å­˜æ–‡ä»¶
            file_id = str(uuid.uuid4())
            temp_filename = f"{file_id}{file_ext}"
            temp_filepath = UPLOAD_DIR / temp_filename
            
            content = await file.read()
            with open(temp_filepath, "wb") as f:
                f.write(content)
            
            file_paths.append(str(temp_filepath))
            
            # åˆ›å»ºæ–‡æ¡£è®°å½•
            document = Document(
                title=file.filename,
                content=f"æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­...",
                user_id=user_id
            )
            db.add(document)
            db.commit()
            db.refresh(document)
            document_ids.append(document.id)
        
        # è§¦å‘æ‰¹é‡å¤„ç†ä»»åŠ¡
        task = batch_process_documents.delay(file_paths, user_id)
        
        return {
            "message": f"æ‰¹é‡å¤„ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œå…± {len(files)} ä¸ªæ–‡ä»¶",
            "task_id": task.id,
            "document_ids": document_ids,
            "status_url": f"/task/status/{task.id}"
        }
        
    except Exception as e:
        # æ¸…ç†å·²ä¿å­˜çš„æ–‡ä»¶
        for file_path in file_paths:
            if os.path.exists(file_path):
                os.remove(file_path)
        
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.get("/task/status/{task_id}")
async def get_task_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€
    
    å‰ç«¯å¯ä»¥é€šè¿‡è½®è¯¢æ­¤æ¥å£è·å–å¤„ç†è¿›åº¦
    """
    try:
        task_result = celery_app.AsyncResult(task_id)
        
        response = {
            "task_id": task_id,
            "status": task_result.state,
            "timestamp": datetime.now().isoformat()
        }
        
        # å¦‚æœä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œæ·»åŠ è¿›åº¦ä¿¡æ¯
        if task_result.state == 'PROGRESS':
            if isinstance(task_result.info, dict):
                response["progress"] = task_result.info.get("progress", 0)
                response["stage"] = task_result.info.get("stage", "å¤„ç†ä¸­")
                response["details"] = task_result.info.get("details", "")
                response["current"] = task_result.info.get("current", 0)
                response["total"] = task_result.info.get("total", 1)
            else:
                response["progress"] = 0
                response["stage"] = "å¤„ç†ä¸­"
        
        # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œæ·»åŠ ç»“æœä¿¡æ¯
        elif task_result.state == 'SUCCESS':
            if isinstance(task_result.result, dict):
                response.update(task_result.result)
            else:
                response["result"] = task_result.result
        
        # å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
        elif task_result.state == 'FAILURE':
            response["error"] = str(task_result.info)
            if hasattr(task_result, "traceback"):
                response["traceback"] = task_result.traceback
        
        return response
        
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return {
            "task_id": task_id,
            "status": "ERROR",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/tasks/queue")
async def get_queue_status():
    """
    è·å–ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
    """
    try:
        # è·å– Celery ç›‘æ§ä¿¡æ¯
        inspector = celery_app.control.inspect()
        
        # è·å–æ´»è·ƒä»»åŠ¡
        active = inspector.active() or {}
        # è·å–é¢„å®šä»»åŠ¡
        scheduled = inspector.scheduled() or {}
        # è·å–ä¿ç•™ä»»åŠ¡
        reserved = inspector.reserved() or {}
        
        # ç»Ÿè®¡é˜Ÿåˆ—é•¿åº¦
        queue_stats = {}
        for worker, tasks in active.items():
            queue_stats[worker] = {
                "active": len(tasks),
                "tasks": [t.get("name", "unknown") for t in tasks[:5]]  # åªæ˜¾ç¤ºå‰5ä¸ª
            }
        
        # è·å– Redis é˜Ÿåˆ—ä¿¡æ¯
        import redis
        redis_client = redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379/0"))
        
        # ç»Ÿè®¡å„ä¸ªé˜Ÿåˆ—çš„é•¿åº¦
        queues = ["celery", "documents", "embeddings", "cleanup"]
        queue_lengths = {}
        for queue in queues:
            try:
                length = redis_client.llen(queue)
                queue_lengths[queue] = length
            except:
                queue_lengths[queue] = 0
        
        return {
            "timestamp": datetime.now().isoformat(),
            "queues": queue_lengths,
            "workers": queue_stats,
            "total_active": sum(len(tasks) for tasks in active.values()),
            "total_scheduled": sum(len(tasks) for tasks in scheduled.values()),
            "total_reserved": sum(len(tasks) for tasks in reserved.values())
        }
        
    except Exception as e:
        logger.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return {"error": str(e)}

# ==================== æ–‡æ¡£ç®¡ç†æ¥å£ ====================

@app.get("/documents/processing")
async def get_processing_documents(
    db: Session = Depends(get_db),
    limit: int = 20,
    offset: int = 0
):
    """è·å–æ­£åœ¨å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨"""
    documents = db.exec(
        select(Document).where(
            Document.content.contains("æ­£åœ¨å¤„ç†ä¸­")
        ).offset(offset).limit(limit)
    ).all()
    
    return {
        "documents": [
            {
                "id": doc.id,
                "title": doc.title,
                "status": "processing",
                "created_at": doc.created_at,
                "user_id": doc.user_id
            }
            for doc in documents
        ],
        "total": len(documents)
    }

@app.get("/documents/recent")
async def get_recent_documents(
    db: Session = Depends(get_db),
    limit: int = 20,
    offset: int = 0
):
    """è·å–æœ€è¿‘å¤„ç†å®Œæˆçš„æ–‡æ¡£"""
    documents = db.exec(
        select(Document).where(
            ~Document.content.contains("æ­£åœ¨å¤„ç†ä¸­")
        ).order_by(Document.created_at.desc()).offset(offset).limit(limit)
    ).all()
    
    return {
        "documents": [
            {
                "id": doc.id,
                "title": doc.title,
                "status": "completed",
                "created_at": doc.created_at,
                "content_preview": doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
                "has_vector": doc.embedding is not None,
                "user_id": doc.user_id
            }
            for doc in documents
        ],
        "total": len(documents)
    }

@app.get("/documents/{document_id}")
async def get_document_detail(
    document_id: int,
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user)
):
    """è·å–æ–‡æ¡£è¯¦æƒ…"""
    from sqlmodel import select
    
    # è·å–æ–‡æ¡£
    document = db.get(Document, document_id)
    
    if not document or document.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
    
    # è·å–æ–‡æ¡£ä¸­çš„å®ä½“
    from models import EntityDocumentLink
    entity_links = db.exec(
        select(EntityDocumentLink).where(
            EntityDocumentLink.document_id == document_id
        )
    ).all()
    
    entities = []
    for link in entity_links:
        entity = db.get(Entity, link.entity_id)
        if entity:
            entities.append({
                "id": entity.id,
                "name": entity.name,
                "type": entity.entity_type,
                "frequency_in_doc": link.frequency_in_doc,
                "significance": link.significance
            })
    
    # è·å–ä¸æ–‡æ¡£ç›¸å…³çš„å…³ç³»
    edges = db.exec(
        select(GraphEdge).where(
            GraphEdge.source_document_id == document_id,
            GraphEdge.user_id == current_user.id
        )
    ).all()
    
    # æ„å»ºæ–‡æ¡£ç»Ÿè®¡
    stats = {
        "content_length": len(document.content) if document.content else 0,
        "entity_count": len(entities),
        "relation_count": len(edges),
        "embedding_status": "å·²å‘é‡åŒ–" if document.embedding else "æœªå‘é‡åŒ–",
        "graph_extracted": "å·²æå–" if document.graph_extracted else "æœªæå–",
        "graph_extraction_time": document.graph_extraction_time.isoformat() if document.graph_extraction_time else None
    }
    
    return {
        "document": {
            "id": document.id,
            "title": document.title,
            "content": document.content,
            "created_at": document.created_at.isoformat() if document.created_at else None,
            "updated_at": document.updated_at.isoformat() if document.updated_at else None,
            "user_id": document.user_id,
            "embedding": "å·²ç”Ÿæˆ" if document.embedding else "æœªç”Ÿæˆ",
            "graph_extracted": document.graph_extracted
        },
        "entities": entities,
        "relations": [edge.to_dict() for edge in edges],
        "stats": stats,
        "preview_contexts": _extract_entity_contexts(document.content, entities[:5])  # æå–å®ä½“å‡ºç°çš„ä¸Šä¸‹æ–‡
    }

def _extract_entity_contexts(content: str, entities: list, context_size: int = 200) -> list:
    """æå–å®ä½“åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„ä¸Šä¸‹æ–‡"""
    if not content or not entities:
        return []
    
    contexts = []
    for entity in entities:
        entity_name = entity["name"]
        # æŸ¥æ‰¾å®ä½“åœ¨å†…å®¹ä¸­çš„ä½ç½®
        pos = content.lower().find(entity_name.lower())
        if pos != -1:
            start = max(0, pos - context_size)
            end = min(len(content), pos + len(entity_name) + context_size)
            context = content[start:end]
            
            # é«˜äº®å®ä½“åç§°
            context = context.replace(entity_name, f"**{entity_name}**")
            
            contexts.append({
                "entity": entity_name,
                "context": f"...{context}...",
                "position": pos
            })
    
    return contexts[:5]  # è¿”å›å‰5ä¸ªä¸Šä¸‹æ–‡

# ==================== æµå¼èŠå¤©æ¥å£ ====================

@app.post("/chat/stream")
async def chat_stream(
    request: dict,
    db: Session = Depends(get_db)
):
    """
    æµå¼èŠå¤©æ¥å£ - æ”¯æŒæ€è€ƒè¿‡ç¨‹å¯è§†åŒ–
    
    è¯·æ±‚ä½“:
    {
        "query": "ç”¨æˆ·çš„é—®é¢˜",
        "mode": "full"  # æˆ– "simple"ï¼Œfullæ˜¾ç¤ºè¯¦ç»†æ€è€ƒè¿‡ç¨‹
    }
    """
    start_time = time.time()
    query = request.get("query", "").strip()
    mode = request.get("mode", "full")  # full: å®Œæ•´æ€è€ƒè¿‡ç¨‹ï¼Œsimple: ç®€åŒ–ç‰ˆ
    top_k = request.get("top_k", 10)
    final_k = request.get("final_k", 3)
    
    if not query:
        return StreamingResponse(
            iter([AgentMessage.error("è¯·è¾“å…¥é—®é¢˜")]),
            media_type="text/plain"
        )
    
    workflow_id = f"chat_stream_{datetime.now().timestamp()}"
    
    try:
        # è·å–èŠå¤©æœåŠ¡
        chat_service = get_agentic_chat_service()
        
        if mode == "full":
            # å®Œæ•´æ€è€ƒè¿‡ç¨‹æ¨¡å¼
            async def generate_full():
                async for message in chat_service.stream_chat_with_thinking(
                    query=query,
                    db=db,
                    top_k=top_k,
                    final_k=final_k,
                    workflow_id=workflow_id
                ):
                    yield message
            
            return StreamingResponse(
                generate_full(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "X-Stream-Mode": "full",
                    "X-Workflow-ID": workflow_id
                }
            )
        else:
            # ç®€åŒ–æ¨¡å¼
            async def generate_simple():
                async for message in chat_service.stream_simple_chat(
                    query=query,
                    db=db,
                    workflow_id=workflow_id
                ):
                    yield message
            
            return StreamingResponse(
                generate_simple(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "X-Stream-Mode": "simple",
                    "X-Workflow-ID": workflow_id
                }
            )
        
    except Exception as e:
        logger.error(f"æµå¼èŠå¤©å¤±è´¥: {e}", exc_info=True)
        return StreamingResponse(
            iter([AgentMessage.error(f"èŠå¤©å¤±è´¥: {str(e)}")]),
            media_type="text/plain"
        )

@app.get("/chat/debug/{workflow_id}")
async def get_chat_debug_info(workflow_id: str):
    """è·å–èŠå¤©è°ƒè¯•ä¿¡æ¯"""
    # è¿™é‡Œå¯ä»¥è¿æ¥æ•°æ®åº“æˆ–Redisè·å–å®é™…çš„å·¥ä½œæµçŠ¶æ€
    # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
    return {
        "workflow_id": workflow_id,
        "status": "completed",
        "timestamp": datetime.now().isoformat(),
        "debug_info": {
            "mode": "full",
            "thinking_steps": [
                {"stage": "thinking_start", "time": "2026-01-01T10:00:00"},
                {"stage": "retrieval", "time": "2026-01-01T10:00:01"},
                {"stage": "generation", "time": "2026-01-01T10:00:03"},
                {"stage": "complete", "time": "2026-01-01T10:00:05"}
            ]
        }
    }

# æ›´æ–°éœ€è¦å®‰å…¨çš„ API ä½¿ç”¨å®‰å…¨æ•°æ®åº“ä¼šè¯
@app.post("/chat/secure")
async def secure_chat(
    request: dict,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_secure_db)
):
    """å®‰å…¨èŠå¤©æ¥å£ - ä½¿ç”¨ RLS ä¿æŠ¤çš„æ•°æ®åº“ä¼šè¯"""
    query = request.get("query", "").strip()
    
    if not query:
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥é—®é¢˜")
    
    try:
        # è®¾ç½®ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå·²åœ¨ä¸­é—´ä»¶ä¸­è®¾ç½®ï¼‰
        # ç›´æ¥ä½¿ç”¨å®‰å…¨æœç´¢
        from services.search import secure_hybrid_search
        
        results = await secure_hybrid_search(
            query=query,
            db=db,
            user_id=current_user.id,
            top_k=10,
            final_k=3
        )
        
        return {
            "query": query,
            "results": results,
            "user_id": current_user.id,
            "documents_found": len(results)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


# ==================== æ™ºèƒ½ä½“ -- æ”¯æŒå·¥å…·è°ƒç”¨ ====================

@app.post("/agent/execute")
async def agent_execute(
    request: dict,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_secure_db)
):
    """
    æ™ºèƒ½ä½“æ‰§è¡Œæ¥å£ - æ”¯æŒå·¥å…·è°ƒç”¨
    
    è¯·æ±‚ä½“:
    {
        "query": "ç”¨æˆ·é—®é¢˜",
        "use_knowledge": true,  # æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“
        "stream": false         # æ˜¯å¦æµå¼è¾“å‡º
    }
    """
    query = request.get("query", "").strip()
    use_knowledge = request.get("use_knowledge", True)
    stream = request.get("stream", False)
    
    if not query:
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥é—®é¢˜")
    
    # è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡
    context = ""
    if use_knowledge:
        from services.search import secure_hybrid_search
        try:
            docs = await secure_hybrid_search(
                query=query,
                db=db,
                user_id=current_user.id,
                top_k=5,
                final_k=2
            )
            if docs:
                context = "\n".join([doc.get('content', '')[:500] for doc in docs[:2]])
        except Exception as e:
            logger.warning(f"çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
    
    if stream:
        # æµå¼å“åº”
        async def event_generator():
            try:
                # åˆ›å»ºå·¥ä½œæµï¼ˆå¸¦writerï¼‰
                from services.agent_graph import get_agent_workflow
                app = get_agent_workflow()
                
                # åˆå§‹åŒ–çŠ¶æ€
                initial_state = {
                    "messages": [HumanMessage(content=query)],
                    "documents": [],
                    "generation": "",
                    "current_node": "start",
                    "node_history": [],
                    "start_time": datetime.now(),
                    "error": None,
                    "retry_count": 0,
                    "is_relevant": None
                }
                
                # æ‰§è¡Œå·¥ä½œæµ
                async for event in app.astream(initial_state, {"db": db}):
                    for key, value in event.items():
                        if key == "generation" and value:
                            yield f"data: {json.dumps({'type': 'chunk', 'data': value})}\n\n"
                        elif key == "tool_calls":
                            for tool_call in value:
                                yield f"data: {json.dumps({'type': 'tool_call', 'data': tool_call})}\n\n"
                        elif key == "tool_results":
                            for tool_result in value:
                                yield f"data: {json.dumps({'type': 'tool_result', 'data': tool_result})}\n\n"
                
                yield f"data: {json.dumps({'type': 'complete', 'data': 'å®Œæˆ'})}\n\n"
                
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'data': f'æ‰§è¡Œå¤±è´¥: {str(e)}'})}\n\n"
        
        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    else:
        # éæµå¼å“åº”
        try:
            from services.agent_graph import get_agent_workflow
            app = get_agent_workflow()
            
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "documents": [],
                "generation": "",
                "current_node": "start",
                "node_history": [],
                "start_time": datetime.now(),
                "error": None,
                "retry_count": 0,
                "is_relevant": None
            }
            
            result = await app.ainvoke(initial_state, {"db": db})
            
            return {
                "success": True,
                "query": query,
                "response": result.get("generation", ""),
                "tools_used": result.get("tool_calls", []),
                "tools_count": len(result.get("tool_calls", [])),
                "tool_results": result.get("tool_results", []),
                "user_id": current_user.id,
                "node_history": result.get("node_history", [])
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"æ™ºèƒ½ä½“æ‰§è¡Œå¤±è´¥: {str(e)}")

@app.get("/agent/tools")
async def list_available_tools(
    current_user: User = Depends(get_current_active_user)
):
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
    tool_manager = get_tool_manager()
    tools = tool_manager.get_tools_description()
    
    return {
        "tools": tools,
        "total": len(tools),
        "user_id": current_user.id
    }

@app.post("/agent/tools/execute")
async def execute_specific_tool(
    request: dict,
    current_user: User = Depends(get_current_active_user)
):
    """ç›´æ¥æ‰§è¡Œç‰¹å®šå·¥å…·"""
    tool_name = request.get("tool_name", "").strip()
    tool_args = request.get("tool_args", {})
    
    if not tool_name:
        raise HTTPException(status_code=400, detail="è¯·æŒ‡å®šå·¥å…·åç§°")
    
    tool_manager = get_tool_manager()
    
    # æ‰§è¡Œå·¥å…·
    result = await tool_manager.execute_tool(tool_name, **tool_args)
    
    return {
        "success": result.get("success", False),
        "tool_name": tool_name,
        "tool_args": tool_args,
        "result": result,
        "user_id": current_user.id,
        "timestamp": datetime.now().isoformat()
    }


# ==================== çŸ¥è¯†å›¾è°± ====================

@app.get("/graph/entities")
async def get_entities(
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user),
    query: Optional[str] = None,
    entity_type: Optional[str] = None,
    limit: int = 50,
    offset: int = 0
):
    """è·å–å®ä½“åˆ—è¡¨"""
    from sqlmodel import select
    
    stmt = select(Entity).where(Entity.user_id == current_user.id)
    
    if query:
        stmt = stmt.where(Entity.name.ilike(f"%{query}%"))
    
    if entity_type:
        stmt = stmt.where(Entity.entity_type == entity_type)
    
    stmt = stmt.offset(offset).limit(limit)
    
    entities = db.exec(stmt).all()
    
    return {
        "entities": [entity.to_dict() for entity in entities],
        "total": len(entities)
    }

@app.get("/graph/edges")
async def get_edges(
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user),
    source_id: Optional[int] = None,
    target_id: Optional[int] = None,
    relation_type: Optional[str] = None,
    limit: int = 100,
    offset: int = 0
):
    """è·å–å…³ç³»è¾¹"""
    from sqlmodel import select
    
    stmt = select(GraphEdge).where(GraphEdge.user_id == current_user.id)
    
    if source_id:
        stmt = stmt.where(GraphEdge.source_id == source_id)
    
    if target_id:
        stmt = stmt.where(GraphEdge.target_id == target_id)
    
    if relation_type:
        stmt = stmt.where(GraphEdge.relation_type == relation_type)
    
    stmt = stmt.offset(offset).limit(limit)
    
    edges = db.exec(stmt).all()
    
    return {
        "edges": [edge.to_dict() for edge in edges],
        "total": len(edges)
    }

@app.get("/graph/data")
async def get_graph_data(
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user),
    document_id: Optional[int] = None,
    include_documents: bool = True  # æ–°å¢å‚æ•°ï¼šæ˜¯å¦åŒ…å«æ–‡æ¡£ä¿¡æ¯
):
    """è·å–å›¾è°±æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
    from sqlmodel import select
    
    # è·å–å®ä½“
    if document_id:
        # è·å–ç‰¹å®šæ–‡æ¡£çš„å®ä½“
        from models import EntityDocumentLink
        stmt = select(Entity).join(EntityDocumentLink).where(
            EntityDocumentLink.document_id == document_id,
            Entity.user_id == current_user.id
        ).limit(50)
    else:
        # è·å–æ‰€æœ‰å®ä½“ï¼ˆæŒ‰é¢‘ç‡æ’åºï¼‰
        stmt = select(Entity).where(
            Entity.user_id == current_user.id
        ).order_by(Entity.frequency.desc()).limit(100)  # å¢åŠ åˆ°100ä¸ª
    
    entities = db.exec(stmt).all()
    
    if not entities:
        return {"nodes": [], "links": []}
    
    entity_ids = [e.id for e in entities]
    
    # è·å–å…³ç³»
    edges = db.exec(
        select(GraphEdge).where(
            or_(
                GraphEdge.source_id.in_(entity_ids),
                GraphEdge.target_id.in_(entity_ids)
            ),
            GraphEdge.user_id == current_user.id
        ).limit(300)
    ).all()
    
    # å¦‚æœè¦æ±‚åŒ…å«æ–‡æ¡£ä¿¡æ¯ï¼Œè·å–å®ä½“çš„å…³è”æ–‡æ¡£
    entity_docs_map = {}
    if include_documents:
        from models import EntityDocumentLink
        # æŸ¥è¯¢æ‰€æœ‰å®ä½“çš„æ–‡æ¡£å…³è”
        doc_links = db.exec(
            select(EntityDocumentLink).where(
                EntityDocumentLink.entity_id.in_(entity_ids)
            )
        ).all()
        
        # æ„å»ºå®ä½“åˆ°æ–‡æ¡£çš„æ˜ å°„
        for link in doc_links:
            if link.entity_id not in entity_docs_map:
                entity_docs_map[link.entity_id] = []
            
            # è·å–æ–‡æ¡£è¯¦æƒ…
            doc = db.get(Document, link.document_id)
            if doc and doc.user_id == current_user.id:  # ç¡®ä¿æ–‡æ¡£å±äºå½“å‰ç”¨æˆ·
                entity_docs_map[link.entity_id].append({
                    "id": doc.id,
                    "title": doc.title,
                    "created_at": doc.created_at.isoformat() if doc.created_at else None,
                    "relevance": link.significance  # å…³è”ç¨‹åº¦
                })
    
    # æ„å»ºèŠ‚ç‚¹æ•°æ®
    nodes = []
    for entity in entities:
        node_data = {
            "id": entity.id,
            "name": entity.name,
            "type": entity.entity_type,
            "description": entity.description,
            "group": _get_entity_group(entity.entity_type),
            "frequency": entity.frequency,
            "confidence": entity.confidence,
            "document_count": len(entity.documents) if hasattr(entity, 'documents') else 0
        }
        
        # æ·»åŠ æ–‡æ¡£ä¿¡æ¯
        if include_documents and entity.id in entity_docs_map:
            docs = entity_docs_map[entity.id]
            node_data["documents"] = docs
            # æŒ‰å…³è”ç¨‹åº¦æ’åºï¼Œå–æœ€ç›¸å…³çš„æ–‡æ¡£
            if docs:
                sorted_docs = sorted(docs, key=lambda x: x.get("relevance", 0), reverse=True)
                node_data["primary_doc_id"] = sorted_docs[0]["id"]
                node_data["primary_doc_title"] = sorted_docs[0]["title"]
        
        nodes.append(node_data)
    
    # æ„å»ºè¾¹æ•°æ®
    links = []
    for edge in edges:
        links.append({
            "source": edge.source_id,
            "target": edge.target_id,
            "relation": edge.relation_type,
            "weight": edge.weight,
            "description": edge.description,
            "source_context": edge.source_context[:100] if edge.source_context else None,
            "source_document_id": edge.source_document_id  # è®°å½•å…³ç³»æ¥æºæ–‡æ¡£
        })
    
    # æ·»åŠ æ–‡æ¡£èŠ‚ç‚¹ï¼ˆå¦‚æœæŒ‡å®šäº†æ–‡æ¡£ï¼‰
    doc_nodes = []
    if document_id:
        doc = db.get(Document, document_id)
        if doc and doc.user_id == current_user.id:
            doc_nodes.append({
                "id": f"doc_{doc.id}",
                "name": doc.title,
                "type": "DOCUMENT",
                "group": 7,  # æ–‡æ¡£ç±»å‹
                "is_document": True,
                "document_id": doc.id,
                "content_preview": doc.content[:200] if doc.content else ""
            })
    
    return {
        "nodes": nodes + doc_nodes,
        "links": links,
        "stats": {
            "total_entities": len(entities),
            "total_edges": len(edges),
            "entity_types": _count_entity_types(entities)
        }
    }

def _get_entity_group(entity_type: str) -> int:
    """æ ¹æ®å®ä½“ç±»å‹è¿”å›ç»„ID"""
    type_groups = {
        "PERSON": 1,
        "ORGANIZATION": 2,
        "CONCEPT": 3,
        "PRODUCT": 4,
        "LOCATION": 5,
        "EVENT": 6
    }
    return type_groups.get(entity_type.upper(), 0)

def _count_entity_types(entities):
    """ç»Ÿè®¡å®ä½“ç±»å‹"""
    counts = {}
    for entity in entities:
        counts[entity.entity_type] = counts.get(entity.entity_type, 0) + 1
    return counts

@app.get("/graph/entity/{entity_id}")
async def get_entity_details(
    entity_id: int,
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user)
):
    """è·å–å®ä½“è¯¦æƒ…"""
    from sqlmodel import select
    
    entity = db.get(Entity, entity_id)
    
    if not entity or entity.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="å®ä½“ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
    
    # è·å–ç›¸å…³å…³ç³»
    outgoing_edges = db.exec(
        select(GraphEdge).where(
            GraphEdge.source_id == entity_id,
            GraphEdge.user_id == current_user.id
        )
    ).all()
    
    incoming_edges = db.exec(
        select(GraphEdge).where(
            GraphEdge.target_id == entity_id,
            GraphEdge.user_id == current_user.id
        )
    ).all()
    
    # è·å–ç›¸å…³æ–‡æ¡£
    from models import EntityDocumentLink
    doc_links = db.exec(
        select(EntityDocumentLink).where(EntityDocumentLink.entity_id == entity_id)
    ).all()
    
    documents = []
    for link in doc_links:
        doc = db.get(Document, link.document_id)
        if doc:
            documents.append({
                "id": doc.id,
                "title": doc.title,
                "content_preview": doc.content[:200] if doc.content else None,
                "created_at": doc.created_at.isoformat() if doc.created_at else None
            })
    
    return {
        "entity": entity.to_dict(),
        "relationships": {
            "outgoing": [edge.to_dict() for edge in outgoing_edges],
            "incoming": [edge.to_dict() for edge in incoming_edges],
            "total": len(outgoing_edges) + len(incoming_edges)
        },
        "documents": documents,
        "stats": {
            "document_count": len(documents),
            "relationship_count": len(outgoing_edges) + len(incoming_edges)
        }
    }

@app.get("/graph/entity/{entity_id}/documents")
async def get_entity_documents(
    entity_id: int,
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user),
    limit: int = 10,
    offset: int = 0
):
    """è·å–å®ä½“å…³è”çš„æ–‡æ¡£åˆ—è¡¨"""
    from sqlmodel import select
    from models import EntityDocumentLink
    
    # æ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    entity = db.get(Entity, entity_id)
    if not entity or entity.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="å®ä½“ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
    
    # è·å–æ–‡æ¡£å…³è”
    doc_links = db.exec(
        select(EntityDocumentLink)
        .where(EntityDocumentLink.entity_id == entity_id)
        .offset(offset)
        .limit(limit)
    ).all()
    
    documents = []
    for link in doc_links:
        doc = db.get(Document, link.document_id)
        if doc and doc.user_id == current_user.id:
            documents.append({
                "id": doc.id,
                "title": doc.title,
                "content_preview": doc.content[:300] if doc.content else "",
                "created_at": doc.created_at.isoformat() if doc.created_at else None,
                "updated_at": doc.updated_at.isoformat() if doc.updated_at else None,
                "relevance": link.significance,
                "frequency_in_doc": link.frequency_in_doc,
                "occurrences": link.occurrences[:5] if link.occurrences else []  # å‰5ä¸ªå‡ºç°ä½ç½®
            })
    
    return {
        "entity": {
            "id": entity.id,
            "name": entity.name,
            "type": entity.entity_type
        },
        "documents": documents,
        "total": len(doc_links)
    }

@app.post("/graph/query")
async def graph_query(
    request: dict,
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user)
):
    """GraphRAG æŸ¥è¯¢"""
    query = request.get("query", "").strip()
    
    if not query:
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
    
    from services.graph_rag import get_graph_rag_service
    
    service = get_graph_rag_service(db)
    result = await service.query(query, current_user.id)
    
    if not result["success"]:
        raise HTTPException(status_code=500, detail=result.get("error", "æŸ¥è¯¢å¤±è´¥"))
    
    return result

@app.post("/graph/extract/{document_id}")
async def extract_graph_from_document(
    document_id: int,
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user)
):
    """æ‰‹åŠ¨è§¦å‘å›¾è°±æå–"""
    from models import Document
    from tasks.document_tasks import extract_graph_from_document
    
    document = db.get(Document, document_id)
    
    if not document or document.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
    
    # è§¦å‘å¼‚æ­¥ä»»åŠ¡
    task = extract_graph_from_document.delay(document_id, current_user.id)
    
    return {
        "message": "çŸ¥è¯†å›¾è°±æå–ä»»åŠ¡å·²å¼€å§‹",
        "task_id": task.id,
        "document_id": document_id,
        "status_url": f"/task/status/{task.id}"
    }

@app.get("/graph/stats")
async def get_graph_stats(
    db: Session = Depends(get_secure_db),
    current_user: User = Depends(get_current_active_user)
):
    """è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
    from sqlmodel import select, func
    
    # å®ä½“ç»Ÿè®¡
    entity_stats = db.exec(
        select(Entity.entity_type, func.count(Entity.id))
        .where(Entity.user_id == current_user.id)
        .group_by(Entity.entity_type)
    ).all()
    
    total_entities = sum(count for _, count in entity_stats)
    
    # å…³ç³»ç»Ÿè®¡
    relation_stats = db.exec(
        select(GraphEdge.relation_type, func.count(GraphEdge.id))
        .where(GraphEdge.user_id == current_user.id)
        .group_by(GraphEdge.relation_type)
    ).all()
    
    total_edges = sum(count for _, count in relation_stats)
    
    # æ–‡æ¡£ç»Ÿè®¡
    doc_stats = db.exec(
        select(func.count(Document.id))
        .where(
            Document.user_id == current_user.id,
            Document.graph_extracted == True
        )
    ).first()
    
    extracted_docs = doc_stats[0] if doc_stats else 0
    
    total_docs = db.exec(
        select(func.count(Document.id))
        .where(Document.user_id == current_user.id)
    ).first()[0]
    
    return {
        "entities": {
            "total": total_entities,
            "by_type": dict(entity_stats)
        },
        "relationships": {
            "total": total_edges,
            "by_type": dict(relation_stats)
        },
        "documents": {
            "total": total_docs,
            "with_graph": extracted_docs,
            "coverage": f"{(extracted_docs / total_docs * 100):.1f}%" if total_docs > 0 else "0%"
        }
    }

@app.post("/graph/batch-extract")
async def batch_extract_graphs(
    request: dict,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_secure_db)
):
    """æ‰¹é‡æå–çŸ¥è¯†å›¾è°±"""
    document_ids = request.get("document_ids", [])
    
    if not document_ids:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æ–‡æ¡£IDåˆ—è¡¨")
    
    task = batch_extract_graphs.delay(document_ids, current_user.id)
    
    return {
        "message": "æ‰¹é‡å›¾è°±æå–ä»»åŠ¡å·²å¼€å§‹",
        "task_id": task.id,
        "document_count": len(document_ids),
        "status_url": f"/task/status/{task.id}"
    }

@app.post("/graph/reprocess-all")
async def reprocess_all_graphs(
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_secure_db)
):
    """é‡æ–°æå–æ‰€æœ‰æ–‡æ¡£çš„çŸ¥è¯†å›¾è°±"""
    task = reprocess_all_graphs.delay(current_user.id)
    
    return {
        "message": "é‡æ–°æå–æ‰€æœ‰æ–‡æ¡£çŸ¥è¯†å›¾è°±ä»»åŠ¡å·²å¼€å§‹",
        "task_id": task.id,
        "status_url": f"/task/status/{task.id}"
    }

@app.post("/graph/cleanup")
async def cleanup_graph(
    cleanup_type: str = "all",
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_secure_db)
):
    """æ¸…ç†çŸ¥è¯†å›¾è°±"""
    if cleanup_type == "entities":
        task = cleanup_orphaned_entities.delay(current_user.id)
    elif cleanup_type == "edges":
        task = cleanup_orphaned_edges.delay(current_user.id)
    elif cleanup_type == "all":
        # å…ˆæ¸…ç†è¾¹ï¼Œå†æ¸…ç†å®ä½“
        task1 = cleanup_orphaned_edges.delay(current_user.id)
        task2 = cleanup_orphaned_entities.delay(current_user.id)
        return {
            "message": "çŸ¥è¯†å›¾è°±æ¸…ç†ä»»åŠ¡å·²å¼€å§‹",
            "tasks": [
                {"type": "edges", "task_id": task1.id},
                {"type": "entities", "task_id": task2.id}
            ],
            "status_urls": [
                f"/task/status/{task1.id}",
                f"/task/status/{task2.id}"
            ]
        }
    else:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ¸…ç†ç±»å‹")
    
    return {
        "message": f"çŸ¥è¯†å›¾è°±æ¸…ç†ä»»åŠ¡å·²å¼€å§‹ ({cleanup_type})",
        "task_id": task.id,
        "status_url": f"/task/status/{task.id}"
    }

# ==================== ä¿ç•™åŸæœ‰æ¥å£ ====================

@app.get("/")
async def root():
    return {"message": "æ¬¢è¿ä½¿ç”¨ KnoSphere API v2.1 - åˆ†å¸ƒå¼å¼‚æ­¥å¤„ç†ç³»ç»Ÿ"}

@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    from core.logger import log_health_check
    system_info = log_health_check()
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    db_ok = False
    try:
        with engine.connect() as conn:
            from sqlmodel import text
            conn.execute(text("SELECT 1"))
            db_ok = True
    except:
        db_ok = False
    
    # æ£€æŸ¥ Redis è¿æ¥
    redis_ok = False
    try:
        import redis
        redis_client = redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379/0"))
        redis_ok = redis_client.ping()
    except:
        redis_ok = False
    
    # æ£€æŸ¥ Celery Worker
    celery_ok = False
    try:
        inspector = celery_app.control.inspect()
        stats = inspector.stats() or {}
        celery_ok = len(stats) > 0
    except:
        celery_ok = False
    
    status = "healthy" if db_ok and redis_ok and celery_ok else "degraded"
    
    return {
        "status": status,
        "service": "KnoSphere API v2.1",
        "timestamp": datetime.now().isoformat(),
        "checks": {
            "database": "healthy" if db_ok else "unhealthy",
            "redis": "healthy" if redis_ok else "unhealthy",
            "celery_workers": "healthy" if celery_ok else "unhealthy",
            "system": system_info
        }
    }

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸš€ å¯åŠ¨ KnoSphere Agentic RAG ç³»ç»Ÿ...")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        reload=True,
        log_config=None  # ä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰çš„æ—¥å¿—
    )
from fastapi import FastAPI, UploadFile, File, Depends, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from contextlib import asynccontextmanager
from sqlmodel import Session, select
from typing import List, Optional
import os
import uuid
import time
from datetime import datetime
from pathlib import Path

# å¯¼å…¥ Celery ä»»åŠ¡
from tasks.document_tasks import process_large_document, batch_process_documents
from tasks.celery_app import celery_app

# å¯¼å…¥å…¶ä»–æ¨¡å—
from core.logger import logger, WorkflowLogger, log_api_request, log_api_response
from services.agent_graph import get_agent_workflow
from services.llm import get_llm_service
from database import init_db, engine, get_session
from models import Document
from services.embedding import generate_vector

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ å¯åŠ¨ KnoSphere API...")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    with engine.connect() as conn:
        from sqlmodel import text
        conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
        conn.commit()
    init_db()
    
    logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    yield
    
    logger.info("ğŸ‘‹ å…³é—­ KnoSphere API...")

app = FastAPI(
    title="KnoSphere API",
    description="2026 ä¼ä¸šçº§æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ - åˆ†å¸ƒå¼å¼‚æ­¥å¤„ç†",
    version="2.1.0",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== å¼‚æ­¥ä¸Šä¼ æ¥å£ ====================

@app.post("/upload/async")
async def upload_large_document_async(
    file: UploadFile = File(...),
    user_id: Optional[int] = None,
    db: Session = Depends(get_session)
):
    """
    å¼‚æ­¥ä¸Šä¼ å¤§æ–‡æ¡£
    
    ç«‹å³è¿”å›ä»»åŠ¡IDï¼Œæ–‡æ¡£åœ¨åå°å¤„ç†
    """
    start_time = time.time()
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.txt', '.md', '.pdf', '.docx'}
    file_ext = os.path.splitext(file.filename)[1].lower()
    
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒæ ¼å¼: {', '.join(allowed_extensions)}"
        )
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    file_id = str(uuid.uuid4())
    temp_filename = f"{file_id}{file_ext}"
    temp_filepath = UPLOAD_DIR / temp_filename
    
    try:
        # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        content = await file.read()
        with open(temp_filepath, "wb") as f:
            f.write(content)
        
        file_size = len(content) / (1024 * 1024)  # MB
        logger.info(f"ğŸ“¥ æ–‡ä»¶å·²ä¿å­˜: {temp_filepath} ({file_size:.2f}MB)")
        
        # åˆ›å»ºæ–‡æ¡£è®°å½•ï¼ˆåˆå§‹çŠ¶æ€ï¼‰
        document = Document(
            title=file.filename,
            content=f"æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­... ({file_size:.2f}MB)",
            user_id=user_id
        )
        db.add(document)
        db.commit()
        db.refresh(document)
        
        # è§¦å‘å¼‚æ­¥å¤„ç†ä»»åŠ¡
        task = process_large_document.delay(
            str(temp_filepath),
            document.id,
            user_id
        )
        
        response_time = time.time() - start_time
        
        log_api_response("/upload/async", 200, response_time)
        
        return {
            "message": "å¤§æ–‡ä»¶å·²è¿›å…¥åå°å¤„ç†æµæ°´çº¿",
            "task_id": task.id,
            "document_id": document.id,
            "filename": file.filename,
            "file_size_mb": round(file_size, 2),
            "estimated_time": "å¤„ç†æ—¶é—´å–å†³äºæ–‡ä»¶å¤§å°å’Œå†…å®¹å¤æ‚åº¦",
            "status_url": f"/task/status/{task.id}",
            "document_url": f"/documents/{document.id}"
        }
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_filepath.exists():
            temp_filepath.unlink()
        
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/upload/batch")
async def upload_batch_documents(
    files: List[UploadFile] = File(...),
    user_id: Optional[int] = None,
    db: Session = Depends(get_session)
):
    """
    æ‰¹é‡ä¸Šä¼ æ–‡æ¡£
    """
    if len(files) > 10:
        raise HTTPException(status_code=400, detail="ä¸€æ¬¡æœ€å¤šä¸Šä¼ 10ä¸ªæ–‡ä»¶")
    
    file_paths = []
    document_ids = []
    
    try:
        for file in files:
            # éªŒè¯æ–‡ä»¶ç±»å‹
            allowed_extensions = {'.txt', '.md', '.pdf', '.docx'}
            file_ext = os.path.splitext(file.filename)[1].lower()
            
            if file_ext not in allowed_extensions:
                raise HTTPException(
                    status_code=400, 
                    detail=f"æ–‡ä»¶ {file.filename} æ ¼å¼ä¸æ”¯æŒ"
                )
            
            # ä¿å­˜æ–‡ä»¶
            file_id = str(uuid.uuid4())
            temp_filename = f"{file_id}{file_ext}"
            temp_filepath = UPLOAD_DIR / temp_filename
            
            content = await file.read()
            with open(temp_filepath, "wb") as f:
                f.write(content)
            
            file_paths.append(str(temp_filepath))
            
            # åˆ›å»ºæ–‡æ¡£è®°å½•
            document = Document(
                title=file.filename,
                content=f"æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­...",
                user_id=user_id
            )
            db.add(document)
            db.commit()
            db.refresh(document)
            document_ids.append(document.id)
        
        # è§¦å‘æ‰¹é‡å¤„ç†ä»»åŠ¡
        task = batch_process_documents.delay(file_paths, user_id)
        
        return {
            "message": f"æ‰¹é‡å¤„ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œå…± {len(files)} ä¸ªæ–‡ä»¶",
            "task_id": task.id,
            "document_ids": document_ids,
            "status_url": f"/task/status/{task.id}"
        }
        
    except Exception as e:
        # æ¸…ç†å·²ä¿å­˜çš„æ–‡ä»¶
        for file_path in file_paths:
            if os.path.exists(file_path):
                os.remove(file_path)
        
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.get("/task/status/{task_id}")
async def get_task_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€
    
    å‰ç«¯å¯ä»¥é€šè¿‡è½®è¯¢æ­¤æ¥å£è·å–å¤„ç†è¿›åº¦
    """
    try:
        task_result = celery_app.AsyncResult(task_id)
        
        response = {
            "task_id": task_id,
            "status": task_result.state,
            "timestamp": datetime.now().isoformat()
        }
        
        # å¦‚æœä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œæ·»åŠ è¿›åº¦ä¿¡æ¯
        if task_result.state == 'PROGRESS':
            if isinstance(task_result.info, dict):
                response["progress"] = task_result.info.get("progress", 0)
                response["stage"] = task_result.info.get("stage", "å¤„ç†ä¸­")
                response["details"] = task_result.info.get("details", "")
                response["current"] = task_result.info.get("current", 0)
                response["total"] = task_result.info.get("total", 1)
            else:
                response["progress"] = 0
                response["stage"] = "å¤„ç†ä¸­"
        
        # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œæ·»åŠ ç»“æœä¿¡æ¯
        elif task_result.state == 'SUCCESS':
            if isinstance(task_result.result, dict):
                response.update(task_result.result)
            else:
                response["result"] = task_result.result
        
        # å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
        elif task_result.state == 'FAILURE':
            response["error"] = str(task_result.info)
            if hasattr(task_result, "traceback"):
                response["traceback"] = task_result.traceback
        
        return response
        
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return {
            "task_id": task_id,
            "status": "ERROR",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/tasks/queue")
async def get_queue_status():
    """
    è·å–ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
    """
    try:
        # è·å– Celery ç›‘æ§ä¿¡æ¯
        inspector = celery_app.control.inspect()
        
        # è·å–æ´»è·ƒä»»åŠ¡
        active = inspector.active() or {}
        # è·å–é¢„å®šä»»åŠ¡
        scheduled = inspector.scheduled() or {}
        # è·å–ä¿ç•™ä»»åŠ¡
        reserved = inspector.reserved() or {}
        
        # ç»Ÿè®¡é˜Ÿåˆ—é•¿åº¦
        queue_stats = {}
        for worker, tasks in active.items():
            queue_stats[worker] = {
                "active": len(tasks),
                "tasks": [t.get("name", "unknown") for t in tasks[:5]]  # åªæ˜¾ç¤ºå‰5ä¸ª
            }
        
        # è·å– Redis é˜Ÿåˆ—ä¿¡æ¯
        import redis
        redis_client = redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379/0"))
        
        # ç»Ÿè®¡å„ä¸ªé˜Ÿåˆ—çš„é•¿åº¦
        queues = ["celery", "documents", "embeddings", "cleanup"]
        queue_lengths = {}
        for queue in queues:
            try:
                length = redis_client.llen(queue)
                queue_lengths[queue] = length
            except:
                queue_lengths[queue] = 0
        
        return {
            "timestamp": datetime.now().isoformat(),
            "queues": queue_lengths,
            "workers": queue_stats,
            "total_active": sum(len(tasks) for tasks in active.values()),
            "total_scheduled": sum(len(tasks) for tasks in scheduled.values()),
            "total_reserved": sum(len(tasks) for tasks in reserved.values())
        }
        
    except Exception as e:
        logger.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return {"error": str(e)}

# ==================== æ–‡æ¡£ç®¡ç†æ¥å£ ====================

@app.get("/documents/processing")
async def get_processing_documents(
    db: Session = Depends(get_session),
    limit: int = 20,
    offset: int = 0
):
    """è·å–æ­£åœ¨å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨"""
    documents = db.exec(
        select(Document).where(
            Document.content.contains("æ­£åœ¨å¤„ç†ä¸­")
        ).offset(offset).limit(limit)
    ).all()
    
    return {
        "documents": [
            {
                "id": doc.id,
                "title": doc.title,
                "status": "processing",
                "created_at": doc.created_at,
                "user_id": doc.user_id
            }
            for doc in documents
        ],
        "total": len(documents)
    }

@app.get("/documents/recent")
async def get_recent_documents(
    db: Session = Depends(get_session),
    limit: int = 20,
    offset: int = 0
):
    """è·å–æœ€è¿‘å¤„ç†å®Œæˆçš„æ–‡æ¡£"""
    documents = db.exec(
        select(Document).where(
            ~Document.content.contains("æ­£åœ¨å¤„ç†ä¸­")
        ).order_by(Document.created_at.desc()).offset(offset).limit(limit)
    ).all()
    
    return {
        "documents": [
            {
                "id": doc.id,
                "title": doc.title,
                "status": "completed",
                "created_at": doc.created_at,
                "content_preview": doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
                "has_vector": doc.embedding is not None,
                "user_id": doc.user_id
            }
            for doc in documents
        ],
        "total": len(documents)
    }

# ==================== ä¿ç•™åŸæœ‰æ¥å£ ====================

@app.get("/")
async def root():
    return {"message": "æ¬¢è¿ä½¿ç”¨ KnoSphere API v2.1 - åˆ†å¸ƒå¼å¼‚æ­¥å¤„ç†ç³»ç»Ÿ"}

@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    from core.logger import log_health_check
    system_info = log_health_check()
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    db_ok = False
    try:
        with engine.connect() as conn:
            from sqlmodel import text
            conn.execute(text("SELECT 1"))
            db_ok = True
    except:
        db_ok = False
    
    # æ£€æŸ¥ Redis è¿æ¥
    redis_ok = False
    try:
        import redis
        redis_client = redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379/0"))
        redis_ok = redis_client.ping()
    except:
        redis_ok = False
    
    # æ£€æŸ¥ Celery Worker
    celery_ok = False
    try:
        inspector = celery_app.control.inspect()
        stats = inspector.stats() or {}
        celery_ok = len(stats) > 0
    except:
        celery_ok = False
    
    status = "healthy" if db_ok and redis_ok and celery_ok else "degraded"
    
    return {
        "status": status,
        "service": "KnoSphere API v2.1",
        "timestamp": datetime.now().isoformat(),
        "checks": {
            "database": "healthy" if db_ok else "unhealthy",
            "redis": "healthy" if redis_ok else "unhealthy",
            "celery_workers": "healthy" if celery_ok else "unhealthy",
            "system": system_info
        }
    }

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸš€ å¯åŠ¨ KnoSphere Agentic RAG ç³»ç»Ÿ...")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        reload=True,
        log_config=None  # ä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰çš„æ—¥å¿—
    )